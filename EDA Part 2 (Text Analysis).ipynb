{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/opt/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "UsageError: Line magic function `%matplotlib.pyplot` not found.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib.pyplot inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'id', 'type', 'date', 'from', 'from_id', 'text', 'Year',\n",
       "       'Month', 'Hour', 'MonthWord', 'Period'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing unnecessary feature\n",
    "\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>date</th>\n",
       "      <th>from</th>\n",
       "      <th>from_id</th>\n",
       "      <th>text</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Hour</th>\n",
       "      <th>MonthWord</th>\n",
       "      <th>Period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>752960</td>\n",
       "      <td>message</td>\n",
       "      <td>2017-04-09T10:22:29</td>\n",
       "      <td>Jiayin</td>\n",
       "      <td>44420247.0</td>\n",
       "      <td>Hello, Jiayin here! Cute pic there btw hahaha</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>Apr</td>\n",
       "      <td>Morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>752961</td>\n",
       "      <td>message</td>\n",
       "      <td>2017-04-09T11:40:25</td>\n",
       "      <td>Chekwei</td>\n",
       "      <td>63910289.0</td>\n",
       "      <td>HEYHEYHEY</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>Apr</td>\n",
       "      <td>Morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>752962</td>\n",
       "      <td>message</td>\n",
       "      <td>2017-04-09T11:40:37</td>\n",
       "      <td>Chekwei</td>\n",
       "      <td>63910289.0</td>\n",
       "      <td>Omggg I don't want to wake up, feeling like DEATH</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>Apr</td>\n",
       "      <td>Morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>752963</td>\n",
       "      <td>message</td>\n",
       "      <td>2017-04-09T11:45:38</td>\n",
       "      <td>Jiayin</td>\n",
       "      <td>44420247.0</td>\n",
       "      <td>Hahaha!! What time did you studied till?</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>Apr</td>\n",
       "      <td>Morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>752964</td>\n",
       "      <td>message</td>\n",
       "      <td>2017-04-09T12:22:29</td>\n",
       "      <td>Chekwei</td>\n",
       "      <td>63910289.0</td>\n",
       "      <td>I slept at 630!</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>Apr</td>\n",
       "      <td>Morning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id     type                 date     from     from_id  \\\n",
       "0  752960  message  2017-04-09T10:22:29   Jiayin  44420247.0   \n",
       "1  752961  message  2017-04-09T11:40:25  Chekwei  63910289.0   \n",
       "2  752962  message  2017-04-09T11:40:37  Chekwei  63910289.0   \n",
       "3  752963  message  2017-04-09T11:45:38   Jiayin  44420247.0   \n",
       "4  752964  message  2017-04-09T12:22:29  Chekwei  63910289.0   \n",
       "\n",
       "                                                text  Year  Month  Hour  \\\n",
       "0      Hello, Jiayin here! Cute pic there btw hahaha  2017      4    10   \n",
       "1                                          HEYHEYHEY  2017      4    11   \n",
       "2  Omggg I don't want to wake up, feeling like DEATH  2017      4    11   \n",
       "3           Hahaha!! What time did you studied till?  2017      4    11   \n",
       "4                                    I slept at 630!  2017      4    12   \n",
       "\n",
       "  MonthWord   Period  \n",
       "0       Apr  Morning  \n",
       "1       Apr  Morning  \n",
       "2       Apr  Morning  \n",
       "3       Apr  Morning  \n",
       "4       Apr  Morning  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting data type to string\n",
    "\n",
    "df['text'] = df['text'].astype('str') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "textList = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')[0:20] #samples of stopwords to be ignored/removed from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"'\n",
    "text_processing method does 3 things: \n",
    "1. remove punctuation\n",
    "2. remove stop words\n",
    "3. return list in clean text words (string)\n",
    "'\"\"\"\n",
    "\n",
    "def text_processing (text):\n",
    "    nopunc = [char for char in text if char not in string.punctuation]\n",
    "    \n",
    "    nopunc = ''.join(nopunc) \n",
    "    #making it become string of words, with blanks in between each word (proper sentence) \n",
    "    \n",
    "    #Example below:     \n",
    "    #['h','e','l','l','o','','c','h','e','k','','w','e','i']\n",
    "    #'hello chek wei'\n",
    "    #now, nopunc is a string form of words\n",
    "    return [word for word in nopunc.split()\n",
    "           if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Hello, Jiayin here! Cute pic there btw hahaha\n",
       "1                                            HEYHEYHEY\n",
       "2    Omggg I don't want to wake up, feeling like DEATH\n",
       "3             Hahaha!! What time did you studied till?\n",
       "4                                      I slept at 630!\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new feature = cleanText by applying the method we created \n",
    "\n",
    "df['cleanText'] = df['text'].apply(text_processing) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            [Hello, Jiayin, Cute, pic, btw, hahaha]\n",
       "1                                        [HEYHEYHEY]\n",
       "2    [Omggg, dont, want, wake, feeling, like, DEATH]\n",
       "3                      [Hahaha, time, studied, till]\n",
       "4                                       [slept, 630]\n",
       "Name: cleanText, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that stopwords are removed \n",
    "\n",
    "df['cleanText'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending all the text messages into one big list\n",
    "# textList is a big list of list of strings, which needs to flatten later\n",
    "\n",
    "for text in df['cleanText']:\n",
    "    textList.append(text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of tokenize strings after flattened\n",
    "\n",
    "from pandas.core.common import flatten\n",
    "flattenTextList = list(flatten(textList)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting all tokenized strings to small caps\n",
    "\n",
    "mapOutput = map(lambda x:x.lower(), flattenTextList) \n",
    "smallflattenTextList = list(mapOutput) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hahaha', 24536),\n",
       " ('haha', 20613),\n",
       " ('ok', 16576),\n",
       " ('like', 12432),\n",
       " ('think', 11473),\n",
       " ('go', 10013),\n",
       " ('nan', 9697),\n",
       " ('😂', 9109),\n",
       " ('one', 9098),\n",
       " ('cause', 7690),\n",
       " ('also', 7289),\n",
       " ('need', 6670),\n",
       " ('okie', 6618),\n",
       " ('ya', 6579),\n",
       " ('bb', 6274),\n",
       " ('time', 5728),\n",
       " ('hehe', 5485),\n",
       " ('hahahaha', 5479),\n",
       " ('omg', 5306),\n",
       " ('eat', 5152)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most common words in list of strings small caps\n",
    "\n",
    "wordCommon = Counter(smallflattenTextList) \n",
    "wordCommon.most_common()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words \t: frequency\n",
      "hello \t: 1357\n",
      "love \t: 948\n",
      "bye\t: 232\n",
      "lunch\t: 1950\n",
      "dinner\t: 2838\n",
      "chek\t: 356\n"
     ]
    }
   ],
   "source": [
    "print('words \\t: frequency')\n",
    "print('hello \\t: ' + str(smallflattenTextList.count('hello')))\n",
    "print('love \\t: ' + str(smallflattenTextList.count('love')))\n",
    "print('bye\\t: ' + str(smallflattenTextList.count('bye')))\n",
    "print('lunch\\t: ' + str(smallflattenTextList.count('lunch')))\n",
    "print('dinner\\t: ' + str(smallflattenTextList.count('dinner')))\n",
    "print('chek\\t: ' + str(smallflattenTextList.count('chek')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Analysis by word counts (Jiayin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                   [Hello, Jiayin, Cute, pic, btw, hahaha]\n",
       "3                             [Hahaha, time, studied, till]\n",
       "9                                  [hope, got, bed, hahaha]\n",
       "10        [supposed, wake, 10, snoozed, till, 12, part, ...\n",
       "17        [Siao, 35, hours, hahaha, unless, need, paper,...\n",
       "                                ...                        \n",
       "227312                    [still, got, lot, maggie, mee, 😂]\n",
       "227316                                        [okie, dokie]\n",
       "227317                                               [Hehe]\n",
       "227320    [Got, 2, small, prawns, scallops, mussels, hah...\n",
       "227323                               [HAHAHA, frozen, kind]\n",
       "Name: cleanText, Length: 106120, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['from']=='Jiayin']['cleanText'] # filter by partner's name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1                                             [HEYHEYHEY]\n",
       "2         [Omggg, dont, want, wake, feeling, like, DEATH]\n",
       "4                                            [slept, 630]\n",
       "5                              [Omg, snoozed, 10am, till]\n",
       "6                                [Really, need, get, bed]\n",
       "                               ...                       \n",
       "227319                                             [meat]\n",
       "227321                                          [mussels]\n",
       "227322                             [atas, suddenly, HAHA]\n",
       "227324                              [going, shower, alrd]\n",
       "227325                                   [facetime, hehe]\n",
       "Name: cleanText, Length: 121152, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['from']=='Chekwei']['cleanText'] # filter by my name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "jiayinTextList =[]\n",
    "for text in df[df['from']=='Jiayin']['cleanText']:\n",
    "    jiayinTextList.append(text) # text list is a list of list of strings, need to flatten - from JY only\n",
    "\n",
    "chekweiTextList = []\n",
    "for text in df[df['from']=='Chekwei']['cleanText']:\n",
    "    chekweiTextList.append(text) # text list is a list of list of strings, need to flatten - from me only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.core.common import flatten\n",
    "jiayinflattenTextList = list(flatten(jiayinTextList)) # list of tokenize strings after flatten\n",
    "chekweiflattenTextList = list(flatten(chekweiTextList)) # list of tokenize strings after flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "jymapOutput = map(lambda x:x.lower(), jiayinflattenTextList) \n",
    "cwmapOutput = map(lambda x:x.lower(), chekweiflattenTextList) \n",
    "\n",
    "jiayinsmallflattenTextList = list(jymapOutput) # list of tokenize strings in small caps\n",
    "chekweismallflattenTextList = list(cwmapOutput) # list of tokenize strings in small caps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hahaha', 16188),\n",
       " ('haha', 11028),\n",
       " ('ok', 7899),\n",
       " ('think', 6715),\n",
       " ('like', 6686),\n",
       " ('😂', 6221),\n",
       " ('one', 4726),\n",
       " ('nan', 4410),\n",
       " ('hahahaha', 4241),\n",
       " ('go', 3898)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 10 most common words in list of strings small caps from Jiayin\n",
    "\n",
    "jywordCommon = Counter(jiayinsmallflattenTextList) \n",
    "jywordCommon.most_common()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('haha', 9585),\n",
       " ('ok', 8677),\n",
       " ('hahaha', 8348),\n",
       " ('go', 6115),\n",
       " ('like', 5746),\n",
       " ('nan', 5233),\n",
       " ('think', 4758),\n",
       " ('one', 4372),\n",
       " ('okie', 4338),\n",
       " ('also', 4237)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 10 most common words in list of strings small caps from Chek\n",
    "\n",
    "cwwordCommon = Counter(chekweismallflattenTextList) \n",
    "cwwordCommon.most_common()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words from JY \t: frequency\n",
      "hi\t\t: 355\n",
      "hey\t\t: 72\n",
      "hahaha\t\t: 16188\n",
      "haha\t\t: 11028\n",
      "😂\t\t: 6221\n",
      "food\t\t: 994\n",
      "\n",
      "\n",
      "words from CW \t: frequency\n",
      "hi\t\t: 304\n",
      "hey\t\t: 228\n",
      "hahaha\t\t: 8348\n",
      "haha\t\t: 9585\n",
      "😂\t\t: 2888\n",
      "food\t\t: 1465\n"
     ]
    }
   ],
   "source": [
    "print('words from JY \\t: frequency')\n",
    "print('hi\\t\\t: ' + str(jiayinsmallflattenTextList.count('hi')))\n",
    "print('hey\\t\\t: ' + str(jiayinsmallflattenTextList.count('hey')))\n",
    "print('hahaha\\t\\t: ' + str(jiayinsmallflattenTextList.count('hahaha')))\n",
    "print('haha\\t\\t: ' + str(jiayinsmallflattenTextList.count('haha')))\n",
    "print('😂\\t\\t: ' + str(jiayinsmallflattenTextList.count('😂')))\n",
    "print('food\\t\\t: ' + str(jiayinsmallflattenTextList.count('food')))\n",
    "\n",
    "print('\\n')\n",
    "print('words from CW \\t: frequency')\n",
    "print('hi\\t\\t: ' + str(chekweismallflattenTextList.count('hi')))\n",
    "print('hey\\t\\t: ' + str(chekweismallflattenTextList.count('hey')))\n",
    "print('hahaha\\t\\t: ' + str(chekweismallflattenTextList.count('hahaha')))\n",
    "print('haha\\t\\t: ' + str(chekweismallflattenTextList.count('haha')))\n",
    "print('😂\\t\\t: ' + str(chekweismallflattenTextList.count('😂')))\n",
    "print('food\\t\\t: ' + str(chekweismallflattenTextList.count('food')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
