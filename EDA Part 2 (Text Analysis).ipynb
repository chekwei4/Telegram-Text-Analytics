{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/opt/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "UsageError: Line magic function `%matplotlib.pyplot` not found.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib.pyplot inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'id', 'type', 'date', 'from', 'from_id', 'text', 'Year',\n",
       "       'Month', 'Hour', 'MonthWord', 'Period'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing unnecessary feature\n",
    "\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>date</th>\n",
       "      <th>from</th>\n",
       "      <th>from_id</th>\n",
       "      <th>text</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Hour</th>\n",
       "      <th>MonthWord</th>\n",
       "      <th>Period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>752960</td>\n",
       "      <td>message</td>\n",
       "      <td>2017-04-09T10:22:29</td>\n",
       "      <td>Jiayin</td>\n",
       "      <td>44420247.0</td>\n",
       "      <td>Hello, Jiayin here! Cute pic there btw hahaha</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>Apr</td>\n",
       "      <td>Morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>752961</td>\n",
       "      <td>message</td>\n",
       "      <td>2017-04-09T11:40:25</td>\n",
       "      <td>Chekwei</td>\n",
       "      <td>63910289.0</td>\n",
       "      <td>HEYHEYHEY</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>Apr</td>\n",
       "      <td>Morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>752962</td>\n",
       "      <td>message</td>\n",
       "      <td>2017-04-09T11:40:37</td>\n",
       "      <td>Chekwei</td>\n",
       "      <td>63910289.0</td>\n",
       "      <td>Omggg I don't want to wake up, feeling like DEATH</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>Apr</td>\n",
       "      <td>Morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>752963</td>\n",
       "      <td>message</td>\n",
       "      <td>2017-04-09T11:45:38</td>\n",
       "      <td>Jiayin</td>\n",
       "      <td>44420247.0</td>\n",
       "      <td>Hahaha!! What time did you studied till?</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>Apr</td>\n",
       "      <td>Morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>752964</td>\n",
       "      <td>message</td>\n",
       "      <td>2017-04-09T12:22:29</td>\n",
       "      <td>Chekwei</td>\n",
       "      <td>63910289.0</td>\n",
       "      <td>I slept at 630!</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>Apr</td>\n",
       "      <td>Morning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id     type                 date     from     from_id  \\\n",
       "0  752960  message  2017-04-09T10:22:29   Jiayin  44420247.0   \n",
       "1  752961  message  2017-04-09T11:40:25  Chekwei  63910289.0   \n",
       "2  752962  message  2017-04-09T11:40:37  Chekwei  63910289.0   \n",
       "3  752963  message  2017-04-09T11:45:38   Jiayin  44420247.0   \n",
       "4  752964  message  2017-04-09T12:22:29  Chekwei  63910289.0   \n",
       "\n",
       "                                                text  Year  Month  Hour  \\\n",
       "0      Hello, Jiayin here! Cute pic there btw hahaha  2017      4    10   \n",
       "1                                          HEYHEYHEY  2017      4    11   \n",
       "2  Omggg I don't want to wake up, feeling like DEATH  2017      4    11   \n",
       "3           Hahaha!! What time did you studied till?  2017      4    11   \n",
       "4                                    I slept at 630!  2017      4    12   \n",
       "\n",
       "  MonthWord   Period  \n",
       "0       Apr  Morning  \n",
       "1       Apr  Morning  \n",
       "2       Apr  Morning  \n",
       "3       Apr  Morning  \n",
       "4       Apr  Morning  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting data type to string\n",
    "\n",
    "df['text'] = df['text'].astype('str') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "textList = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english') #stopwords to be ignored/removed from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"'\n",
    "text_processing method does 3 things: \n",
    "1. remove punctuation\n",
    "2. remove stop words\n",
    "3. return list in clean text words (string)\n",
    "'\"\"\"\n",
    "\n",
    "def text_processing (text):\n",
    "    nopunc = [char for char in text if char not in string.punctuation]\n",
    "    \n",
    "    nopunc = ''.join(nopunc) \n",
    "    #making it become string of words, with blanks in between each word (proper sentence) \n",
    "    \n",
    "    #Example below:     \n",
    "    #['h','e','l','l','o','','c','h','e','k','','w','e','i']\n",
    "    #'hello chek wei'\n",
    "    #now, nopunc is a string form of words\n",
    "    return [word for word in nopunc.split()\n",
    "           if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Hello, Jiayin here! Cute pic there btw hahaha\n",
       "1                                            HEYHEYHEY\n",
       "2    Omggg I don't want to wake up, feeling like DEATH\n",
       "3             Hahaha!! What time did you studied till?\n",
       "4                                      I slept at 630!\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new feature = cleanText by applying the method we created \n",
    "\n",
    "df['cleanText'] = df['text'].apply(text_processing) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            [Hello, Jiayin, Cute, pic, btw, hahaha]\n",
       "1                                        [HEYHEYHEY]\n",
       "2    [Omggg, dont, want, wake, feeling, like, DEATH]\n",
       "3                      [Hahaha, time, studied, till]\n",
       "4                                       [slept, 630]\n",
       "Name: cleanText, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that stopwords are removed \n",
    "\n",
    "df['cleanText'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending all the text messages into one big list\n",
    "# textList is a big list of list of strings, which needs to flatten later\n",
    "\n",
    "for text in df['cleanText']:\n",
    "    textList.append(text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of tokenize strings after flattened\n",
    "\n",
    "from pandas.core.common import flatten\n",
    "flattenTextList = list(flatten(textList)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting all tokenized strings to small caps\n",
    "\n",
    "mapOutput = map(lambda x:x.lower(), flattenTextList) \n",
    "smallflattenTextList = list(mapOutput) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hahaha', 24536),\n",
       " ('haha', 20613),\n",
       " ('ok', 16576),\n",
       " ('like', 12432),\n",
       " ('think', 11473),\n",
       " ('go', 10013),\n",
       " ('nan', 9697),\n",
       " ('😂', 9109),\n",
       " ('one', 9098),\n",
       " ('cause', 7690),\n",
       " ('also', 7289),\n",
       " ('need', 6670),\n",
       " ('okie', 6618),\n",
       " ('ya', 6579),\n",
       " ('bb', 6274),\n",
       " ('time', 5728),\n",
       " ('hehe', 5485),\n",
       " ('hahahaha', 5479),\n",
       " ('omg', 5306),\n",
       " ('eat', 5152),\n",
       " ('dont', 5050),\n",
       " ('see', 4511),\n",
       " ('still', 4385),\n",
       " ('right', 4277),\n",
       " ('yes', 4229),\n",
       " ('want', 4213),\n",
       " ('maybe', 4197),\n",
       " ('don’t', 4024),\n",
       " ('hehehe', 3936),\n",
       " ('got', 3860),\n",
       " ('oh', 3709),\n",
       " ('buy', 3707),\n",
       " ('legit', 3683),\n",
       " ('good', 3578),\n",
       " ('home', 3576),\n",
       " ('later', 3403),\n",
       " ('get', 3304),\n",
       " ('it’s', 3194),\n",
       " ('text', 3113),\n",
       " ('alrd', 3094),\n",
       " ('know', 3089),\n",
       " ('wah', 3079),\n",
       " ('back', 3072),\n",
       " ('dokie', 3025),\n",
       " ('la', 3018),\n",
       " ('first', 3010),\n",
       " ('really', 2956),\n",
       " ('work', 2941),\n",
       " ('actually', 2907),\n",
       " ('cannot', 2895),\n",
       " ('since', 2861),\n",
       " ('yup', 2846),\n",
       " ('dinner', 2838),\n",
       " ('i’m', 2754),\n",
       " ('type', 2716),\n",
       " ('quite', 2697),\n",
       " ('alr', 2635),\n",
       " ('tmr', 2593),\n",
       " ('damn', 2554),\n",
       " ('sleep', 2520),\n",
       " ('take', 2477),\n",
       " ('day', 2459),\n",
       " ('food', 2459),\n",
       " ('say', 2453),\n",
       " ('kind', 2426),\n",
       " ('im', 2308),\n",
       " ('ah', 2284),\n",
       " ('today', 2261),\n",
       " ('ohhh', 2240),\n",
       " ('house', 2229),\n",
       " ('going', 2184),\n",
       " ('next', 2162),\n",
       " ('wait', 2150),\n",
       " ('much', 2086),\n",
       " ('leh', 2061),\n",
       " ('last', 2025),\n",
       " ('even', 1992),\n",
       " ('never', 1988),\n",
       " ('always', 1961),\n",
       " ('lunch', 1950),\n",
       " ('tell', 1917),\n",
       " ('ask', 1875),\n",
       " ('feel', 1860),\n",
       " ('come', 1848),\n",
       " ('yeah', 1833),\n",
       " ('gonna', 1823),\n",
       " ('night', 1810),\n",
       " ('let', 1809),\n",
       " ('already', 1788),\n",
       " ('left', 1772),\n",
       " ('means', 1767),\n",
       " ('baby', 1747),\n",
       " ('tonight', 1728),\n",
       " ('liao', 1721),\n",
       " ('make', 1706),\n",
       " ('thought', 1671),\n",
       " ('sure', 1662),\n",
       " ('plus', 1625),\n",
       " ('hiak', 1612),\n",
       " ('went', 1595),\n",
       " ('look', 1593),\n",
       " ('long', 1587),\n",
       " ('use', 1572),\n",
       " ('thats', 1558),\n",
       " ('better', 1557),\n",
       " ('morning', 1556),\n",
       " ('didnt', 1526),\n",
       " ('said', 1512),\n",
       " ('wow', 1507),\n",
       " ('rly', 1497),\n",
       " ('urps', 1491),\n",
       " ('😌', 1471),\n",
       " ('remember', 1444),\n",
       " ('told', 1439),\n",
       " ('meet', 1402),\n",
       " ('hahahahaha', 1398),\n",
       " ('nice', 1396),\n",
       " ('eating', 1395),\n",
       " ('try', 1385),\n",
       " ('thing', 1372),\n",
       " ('2', 1370),\n",
       " ('hello', 1357),\n",
       " ('hor', 1355),\n",
       " ('lot', 1347),\n",
       " ('soon', 1328),\n",
       " ('stuff', 1306),\n",
       " ('leave', 1306),\n",
       " ('people', 1300),\n",
       " ('two', 1272),\n",
       " ('money', 1261),\n",
       " ('mum', 1261),\n",
       " ('hashtag', 1260),\n",
       " ('sounds', 1257),\n",
       " ('train', 1254),\n",
       " ('confirm', 1240),\n",
       " ('end', 1225),\n",
       " ('anyway', 1222),\n",
       " ('that’s', 1217),\n",
       " ('bad', 1210),\n",
       " ('idk', 1210),\n",
       " ('okok', 1209),\n",
       " ('class', 1206),\n",
       " ('find', 1187),\n",
       " ('please', 1185),\n",
       " ('looks', 1183),\n",
       " ('probably', 1180),\n",
       " ('us', 1179),\n",
       " ('🌚', 1179),\n",
       " ('office', 1170),\n",
       " ('hope', 1161),\n",
       " ('drink', 1150),\n",
       " ('saw', 1142),\n",
       " ('face', 1140),\n",
       " ('anything', 1140),\n",
       " ('something', 1138),\n",
       " ('didn’t', 1138),\n",
       " ('bring', 1135),\n",
       " ('late', 1133),\n",
       " ('done', 1120),\n",
       " ('thanks', 1116),\n",
       " ('days', 1099),\n",
       " ('link', 1098),\n",
       " ('guess', 1090),\n",
       " ('friends', 1083),\n",
       " ('must', 1073),\n",
       " ('yaaa', 1071),\n",
       " ('check', 1066),\n",
       " ('hair', 1052),\n",
       " ('till', 1034),\n",
       " ('bought', 1022),\n",
       " ('wont', 1018),\n",
       " ('wanted', 1016),\n",
       " ('wanna', 1012),\n",
       " ('early', 1011),\n",
       " ('1', 992),\n",
       " ('phone', 987),\n",
       " ('help', 979),\n",
       " ('yet', 977),\n",
       " ('shower', 973),\n",
       " ('cheryl', 964),\n",
       " ('week', 956),\n",
       " ('pls', 953),\n",
       " ('give', 953),\n",
       " ('love', 948),\n",
       " ('bed', 944),\n",
       " ('many', 937),\n",
       " ('super', 932),\n",
       " ('instead', 924),\n",
       " ('watch', 923),\n",
       " ('room', 919),\n",
       " ('goodnight', 912),\n",
       " ('bus', 906),\n",
       " ('3', 906),\n",
       " ('way', 904),\n",
       " ('serene', 898),\n",
       " ('change', 890),\n",
       " ('bit', 889),\n",
       " ('another', 887),\n",
       " ('life', 881),\n",
       " ('place', 881),\n",
       " ('ig', 878),\n",
       " ('mean', 875),\n",
       " ('things', 869),\n",
       " ('put', 867),\n",
       " ('fast', 867),\n",
       " ('well', 865),\n",
       " ('enough', 863),\n",
       " ('shall', 860),\n",
       " ('every', 859),\n",
       " ('true', 854),\n",
       " ('reached', 849),\n",
       " ('ate', 845),\n",
       " ('call', 838),\n",
       " ('would', 838),\n",
       " ('won’t', 835),\n",
       " ('abt', 824),\n",
       " ('new', 821),\n",
       " ('reply', 810),\n",
       " ('thinking', 805),\n",
       " ('inside', 793),\n",
       " ('hahah', 788),\n",
       " ('around', 787),\n",
       " ('huh', 783),\n",
       " ('reach', 772),\n",
       " ('waiting', 767),\n",
       " ('stop', 762),\n",
       " ('wake', 760),\n",
       " ('can’t', 759),\n",
       " ('free', 754),\n",
       " ('mins', 753),\n",
       " ('gg', 750),\n",
       " ('sleeping', 748),\n",
       " ('keep', 747),\n",
       " ('anw', 745),\n",
       " ('friend', 744),\n",
       " ('dyou', 742),\n",
       " ('walk', 730),\n",
       " ('send', 719),\n",
       " ('babyyy', 714),\n",
       " ('funny', 704),\n",
       " ('rice', 696),\n",
       " ('shag', 694),\n",
       " ('nvm', 691),\n",
       " ('though', 690),\n",
       " ('stay', 686),\n",
       " ('meeting', 685),\n",
       " ('says', 682),\n",
       " ('chicken', 682),\n",
       " ('5', 678),\n",
       " ('cant', 676),\n",
       " ('dk', 673),\n",
       " ('kidding', 665),\n",
       " ('away', 665),\n",
       " ('person', 665),\n",
       " ('nothing', 661),\n",
       " ('hi', 659),\n",
       " ('pay', 658),\n",
       " ('book', 658),\n",
       " ('10', 656),\n",
       " ('talk', 656),\n",
       " ('theres', 654),\n",
       " ('else', 651),\n",
       " ('play', 649),\n",
       " ('finished', 649),\n",
       " ('usually', 645),\n",
       " ('card', 641),\n",
       " ('part', 640),\n",
       " ('nope', 639),\n",
       " ('aiyo', 636),\n",
       " ('run', 634),\n",
       " ('yesterday', 633),\n",
       " ('show', 632),\n",
       " ('mrt', 632),\n",
       " ('irene', 632),\n",
       " ('start', 631),\n",
       " ('sound', 626),\n",
       " ('asked', 626),\n",
       " ('wear', 623),\n",
       " ('de', 622),\n",
       " ('cui', 619),\n",
       " ('gym', 617),\n",
       " ('4', 616),\n",
       " ('year', 615),\n",
       " ('set', 613),\n",
       " ('i’ll', 612),\n",
       " ('😘', 609),\n",
       " ('feeling', 605),\n",
       " ('hungry', 605),\n",
       " ('sia', 605),\n",
       " ('coming', 603),\n",
       " ('yishun', 603),\n",
       " ('sth', 603),\n",
       " ('tomorrow', 602),\n",
       " ('omggg', 599),\n",
       " ('best', 594),\n",
       " ('finish', 593),\n",
       " ('big', 589),\n",
       " ('weekend', 588),\n",
       " ('saying', 587),\n",
       " ('less', 587),\n",
       " ('there’s', 585),\n",
       " ('together', 583),\n",
       " ('trying', 581),\n",
       " ('everything', 579),\n",
       " ('sorry', 579),\n",
       " ('water', 578),\n",
       " ('haven’t', 576),\n",
       " ('whether', 570),\n",
       " ('cute', 569),\n",
       " ('guy', 565),\n",
       " ('talking', 562),\n",
       " ('getting', 555),\n",
       " ('queue', 548),\n",
       " ('laaa', 548),\n",
       " ('full', 547),\n",
       " ('hopefully', 547),\n",
       " ('friday', 546),\n",
       " ('someone', 546),\n",
       " ('shit', 544),\n",
       " ('might', 543),\n",
       " ('photo', 541),\n",
       " ('whole', 541),\n",
       " ('havent', 539),\n",
       " ('bishan', 539),\n",
       " ('happy', 536),\n",
       " ('totally', 535),\n",
       " ('read', 534),\n",
       " ('case', 529),\n",
       " ('ahhh', 528),\n",
       " ('coffee', 523),\n",
       " ('woke', 519),\n",
       " ('suspect', 517),\n",
       " ('yknow', 514),\n",
       " ('mother', 514),\n",
       " ('whats', 511),\n",
       " ('jb', 511),\n",
       " ('tired', 510),\n",
       " ('sunday', 509),\n",
       " ('shop', 508),\n",
       " ('side', 505),\n",
       " ('seems', 505),\n",
       " ('walking', 502),\n",
       " ('lehhh', 501),\n",
       " ('save', 500),\n",
       " ('realize', 499),\n",
       " ('may', 496),\n",
       " ('clothes', 496),\n",
       " ('took', 494),\n",
       " ('open', 494),\n",
       " ('arnd', 493),\n",
       " ('small', 491),\n",
       " ('whatever', 490),\n",
       " ('y’all', 490),\n",
       " ('school', 489),\n",
       " ('6', 488),\n",
       " ('order', 488),\n",
       " ('guys', 487),\n",
       " ('times', 486),\n",
       " ('hahahah', 484),\n",
       " ('hahahahahaha', 480),\n",
       " ('😏', 475),\n",
       " ('pretty', 473),\n",
       " ('bag', 473),\n",
       " ('bread', 473),\n",
       " ('ill', 471),\n",
       " ('eyes', 471),\n",
       " ('ended', 469),\n",
       " ('running', 468),\n",
       " ('least', 468),\n",
       " ('😒', 466),\n",
       " ('birthday', 466),\n",
       " ('could', 465),\n",
       " ('khatib', 465),\n",
       " ('annoying', 463),\n",
       " ('grab', 463),\n",
       " ('far', 462),\n",
       " ('spend', 460),\n",
       " ('v', 458),\n",
       " ('old', 456),\n",
       " ('hard', 456),\n",
       " ('hours', 455),\n",
       " ('hehehehe', 453),\n",
       " ('earlier', 452),\n",
       " ('almost', 449),\n",
       " ('watching', 447),\n",
       " ('plan', 444),\n",
       " ('ohhhh', 444),\n",
       " ('level', 441),\n",
       " ('rest', 439),\n",
       " ('share', 438),\n",
       " ('what’s', 438),\n",
       " ('leaving', 437),\n",
       " ('used', 434),\n",
       " ('photos', 433),\n",
       " ('worth', 432),\n",
       " ('everyone', 432),\n",
       " ('different', 430),\n",
       " ('month', 429),\n",
       " ('came', 429),\n",
       " ('parents', 426),\n",
       " ('sg', 425),\n",
       " ('hotel', 425),\n",
       " ('half', 424),\n",
       " ('slept', 423),\n",
       " ('believe', 419),\n",
       " ('real', 419),\n",
       " ('looking', 417),\n",
       " ('using', 411),\n",
       " ('price', 411),\n",
       " ('soup', 411),\n",
       " ('lol', 409),\n",
       " ('course', 409),\n",
       " ('wrong', 407),\n",
       " ('worry', 407),\n",
       " ('pack', 407),\n",
       " ('scared', 404),\n",
       " ('trip', 403),\n",
       " ('saturday', 403),\n",
       " ('period', 401),\n",
       " ('jiayou', 400),\n",
       " ('thank', 399),\n",
       " ('taking', 396),\n",
       " ('shes', 395),\n",
       " ('sent', 394),\n",
       " ('movie', 393),\n",
       " ('head', 392),\n",
       " ('forgot', 391),\n",
       " ('name', 391),\n",
       " ('suddenly', 391),\n",
       " ('near', 389),\n",
       " ('burst', 389),\n",
       " ('😢', 388),\n",
       " ('idw', 388),\n",
       " ('tickets', 388),\n",
       " ('bah', 385),\n",
       " ('job', 383),\n",
       " ('sat', 383),\n",
       " ('otw', 383),\n",
       " ('little', 383),\n",
       " ('point', 379),\n",
       " ('let’s', 379),\n",
       " ('7', 378),\n",
       " ('years', 377),\n",
       " ('cut', 377),\n",
       " ('mind', 376),\n",
       " ('sad', 374),\n",
       " ('20', 374),\n",
       " ('8', 373),\n",
       " ('cook', 373),\n",
       " ('game', 373),\n",
       " ('without', 372),\n",
       " ('hot', 372),\n",
       " ('ago', 371),\n",
       " ('spicy', 371),\n",
       " ('lame', 370),\n",
       " ('pang', 369),\n",
       " ('asking', 367),\n",
       " ('sian', 367),\n",
       " ('telling', 367),\n",
       " ('cheap', 366),\n",
       " ('playing', 366),\n",
       " ('pass', 366),\n",
       " ('reaching', 366),\n",
       " ('unless', 365),\n",
       " ('bro', 365),\n",
       " ('yall', 364),\n",
       " ('lazy', 363),\n",
       " ('definitely', 362),\n",
       " ('post', 362),\n",
       " ('ever', 359),\n",
       " ('chek', 356),\n",
       " ('she’s', 356),\n",
       " ('siaaa', 354),\n",
       " ('cancel', 352),\n",
       " ('working', 351),\n",
       " ('chance', 349),\n",
       " ('miss', 349),\n",
       " ('gang', 348),\n",
       " ('number', 348),\n",
       " ('outside', 347),\n",
       " ('wonder', 346),\n",
       " ('decide', 346),\n",
       " ('black', 345),\n",
       " ('enjoy', 345),\n",
       " ('ones', 344),\n",
       " ('round', 344),\n",
       " ('lying', 343),\n",
       " ('sweet', 343),\n",
       " ('town', 343),\n",
       " ('expensive', 342),\n",
       " ('study', 340),\n",
       " ('second', 340),\n",
       " ('bkk', 340),\n",
       " ('high', 339),\n",
       " ('story', 337),\n",
       " ('mine', 337),\n",
       " ('stomach', 336),\n",
       " ('12', 334),\n",
       " ('np', 334),\n",
       " ('awake', 333),\n",
       " ('close', 333),\n",
       " ('either', 333),\n",
       " ('normal', 331),\n",
       " ('noodles', 331),\n",
       " ('app', 331),\n",
       " ('showering', 331),\n",
       " ('weeks', 330),\n",
       " ('asleep', 330),\n",
       " ('lucky', 329),\n",
       " ('monday', 327),\n",
       " ('sometimes', 327),\n",
       " ('🤔', 327),\n",
       " ('sense', 326),\n",
       " ('imagine', 326),\n",
       " ('wash', 324),\n",
       " ('continue', 324),\n",
       " ('duper', 323),\n",
       " ('choose', 323),\n",
       " ('fine', 322),\n",
       " ('drinking', 321),\n",
       " ('sit', 319),\n",
       " ('email', 318),\n",
       " ('macs', 316),\n",
       " ('short', 315),\n",
       " ('cold', 315),\n",
       " ('become', 312),\n",
       " ('man', 312),\n",
       " ('win', 312),\n",
       " ('mah', 311),\n",
       " ('months', 310),\n",
       " ('meh', 308),\n",
       " ('colleagues', 308),\n",
       " ('alone', 305),\n",
       " ('☺️', 304),\n",
       " ('sister', 304),\n",
       " ('add', 303),\n",
       " ('fish', 303),\n",
       " ('faster', 302),\n",
       " ('recently', 302),\n",
       " ('buying', 302),\n",
       " ('how’s', 302),\n",
       " ('hey', 300),\n",
       " ('quickly', 300),\n",
       " ('feels', 300),\n",
       " ('dw', 298),\n",
       " ('bf', 298),\n",
       " ('especially', 297),\n",
       " ('idea', 296),\n",
       " ('awkward', 294),\n",
       " ('kekeke', 294),\n",
       " ('comes', 293),\n",
       " ('table', 293),\n",
       " ('random', 293),\n",
       " ('door', 293),\n",
       " ('family', 292),\n",
       " ('15', 292),\n",
       " ('pax', 291),\n",
       " ('aiya', 290),\n",
       " ('google', 290),\n",
       " ('worries', 290),\n",
       " ('colleague', 290),\n",
       " ('lo', 289),\n",
       " ('makes', 288),\n",
       " ('mj', 288),\n",
       " ('easy', 287),\n",
       " ('straight', 286),\n",
       " ('isnt', 286),\n",
       " ('car', 286),\n",
       " ('started', 284),\n",
       " ('shoes', 284),\n",
       " ('toilet', 284),\n",
       " ('30', 282),\n",
       " ('slowly', 282),\n",
       " ('size', 282),\n",
       " ('afternoon', 282),\n",
       " ('body', 278),\n",
       " ('settle', 278),\n",
       " ('meal', 278),\n",
       " ('breakfast', 278),\n",
       " ('wants', 278),\n",
       " ('pic', 277),\n",
       " ('usual', 276),\n",
       " ('laptop', 276),\n",
       " ('travel', 275),\n",
       " ('top', 273),\n",
       " ('cake', 273),\n",
       " ('area', 272),\n",
       " ('account', 272),\n",
       " ('tgt', 270),\n",
       " ('le', 270),\n",
       " ('supposed', 269),\n",
       " ('finally', 269),\n",
       " ('serious', 269),\n",
       " ('ice', 269),\n",
       " ('🤪', 268),\n",
       " ('ready', 267),\n",
       " ('cup', 267),\n",
       " ('made', 266),\n",
       " ('changed', 266),\n",
       " ('front', 265),\n",
       " ('timing', 265),\n",
       " ('gave', 265),\n",
       " ('sitting', 265),\n",
       " ('bbt', 265),\n",
       " ('weird', 264),\n",
       " ('found', 264),\n",
       " ('hour', 263),\n",
       " ('three', 262),\n",
       " ('egg', 261),\n",
       " ('tea', 261),\n",
       " ('china', 261),\n",
       " ('happened', 259),\n",
       " ('felt', 259),\n",
       " ('keke', 258),\n",
       " ('poop', 258),\n",
       " ('girls', 257),\n",
       " ('fall', 257),\n",
       " ('aka', 257),\n",
       " ('ahead', 256),\n",
       " ('girl', 255),\n",
       " ('ex', 255),\n",
       " ('promo', 255),\n",
       " ('white', 254),\n",
       " ('care', 254),\n",
       " ('line', 254),\n",
       " ('fifa', 252),\n",
       " ('lie', 252),\n",
       " ('lose', 251),\n",
       " ('waste', 250),\n",
       " ('floor', 250),\n",
       " ('ded', 249),\n",
       " ('fella', 248),\n",
       " ('nap', 248),\n",
       " ('understand', 248),\n",
       " ('angry', 248),\n",
       " ('fat', 248),\n",
       " ('color', 247),\n",
       " ('tuition', 247),\n",
       " ('planning', 246),\n",
       " ('air', 246),\n",
       " ('awhile', 245),\n",
       " ('forget', 245),\n",
       " ('fun', 245),\n",
       " ('break', 245),\n",
       " ('dry', 245),\n",
       " ('delivery', 245),\n",
       " ('kid', 244),\n",
       " ('drinks', 244),\n",
       " ('chat', 244),\n",
       " ('heart', 243),\n",
       " ('cheaper', 243),\n",
       " ('nooo', 243),\n",
       " ('except', 242),\n",
       " ('called', 242),\n",
       " ('daebak', 241),\n",
       " ('studying', 240),\n",
       " ('anyhow', 240),\n",
       " ('team', 240),\n",
       " ('siao', 239),\n",
       " ('pig', 239),\n",
       " ('heard', 236),\n",
       " ('die', 236),\n",
       " ('doesnt', 236),\n",
       " ('gf', 236),\n",
       " ('moment', 236),\n",
       " ('met', 236),\n",
       " ('fries', 236),\n",
       " ('boss', 236),\n",
       " ('exercise', 236),\n",
       " ('laugh', 235),\n",
       " ('wearing', 235),\n",
       " ('doctor', 235),\n",
       " ('jo', 235),\n",
       " ('brought', 234),\n",
       " ('box', 234),\n",
       " ('drop', 233),\n",
       " ('pee', 233),\n",
       " ('proper', 232),\n",
       " ('bye', 232),\n",
       " ('yaye', 231),\n",
       " ('blue', 230),\n",
       " ('taste', 230),\n",
       " ('fav', 230),\n",
       " ('fried', 230),\n",
       " ('50', 229),\n",
       " ('group', 229),\n",
       " ('making', 229),\n",
       " ('past', 228),\n",
       " ('turn', 228),\n",
       " ('😘💓', 228),\n",
       " ('chill', 227),\n",
       " ('pick', 227),\n",
       " ('btw', 225),\n",
       " ('knows', 225),\n",
       " ('😂😂😂', 225),\n",
       " ('simi', 225),\n",
       " ('weekends', 224),\n",
       " ('collect', 224),\n",
       " ('sell', 223),\n",
       " ('code', 223),\n",
       " ('self', 222),\n",
       " ('kept', 221),\n",
       " ('smu', 220),\n",
       " ('live', 220),\n",
       " ('bottle', 220),\n",
       " ('💓', 220),\n",
       " ('question', 219),\n",
       " ('great', 219),\n",
       " ('booked', 218),\n",
       " ('seeing', 218),\n",
       " ('living', 218),\n",
       " ('needs', 218),\n",
       " ('weight', 218),\n",
       " ('hand', 218),\n",
       " ('cream', 218),\n",
       " ('hmm', 217),\n",
       " ('100', 217),\n",
       " ('others', 216),\n",
       " ('tried', 216),\n",
       " ('chop', 216),\n",
       " ('rude', 216),\n",
       " ('zero', 215),\n",
       " ('lil', 215),\n",
       " ('remind', 215),\n",
       " ('agree', 215),\n",
       " ('online', 214),\n",
       " ('cheng', 214),\n",
       " ('milk', 213),\n",
       " ('join', 213),\n",
       " ('effort', 212),\n",
       " ('carry', 212),\n",
       " ('weather', 212),\n",
       " ('checked', 212),\n",
       " ('meat', 212),\n",
       " ('shopping', 211),\n",
       " ('company', 211),\n",
       " ('sai', 211),\n",
       " ('hoho', 211),\n",
       " ('kids', 210),\n",
       " ('mlxg', 210),\n",
       " ('army', 210),\n",
       " ('city', 210),\n",
       " ('mac', 209),\n",
       " ('9', 209),\n",
       " ('clear', 208),\n",
       " ('11', 208),\n",
       " ('hes', 208),\n",
       " ('yoga', 208),\n",
       " ('staycay', 208),\n",
       " ('clean', 206),\n",
       " ('hug', 206),\n",
       " ('nth', 206),\n",
       " ('stupid', 206),\n",
       " ('goodie', 206),\n",
       " ('youuu', 205),\n",
       " ('sch', 205),\n",
       " ('huge', 205),\n",
       " ('xiao', 205),\n",
       " ('💁🏻', 205),\n",
       " ('red', 205),\n",
       " ('wahhh', 205),\n",
       " ('spent', 204),\n",
       " ('funky', 204),\n",
       " ('joke', 204),\n",
       " ('forever', 204),\n",
       " ('sun', 204),\n",
       " ('treat', 204),\n",
       " ('he’s', 204),\n",
       " ('hows', 203),\n",
       " ('mask', 203),\n",
       " ('single', 202),\n",
       " ('mad', 201),\n",
       " ('hear', 201),\n",
       " ('toh', 201),\n",
       " ('omgard', 201),\n",
       " ('decided', 200),\n",
       " ('😍', 200),\n",
       " ('cmi', 200),\n",
       " ('hahahahahahaha', 200),\n",
       " ('classes', 199),\n",
       " ('touch', 199),\n",
       " ('hit', 199),\n",
       " ('throw', 199),\n",
       " ('rather', 199),\n",
       " ('items', 199),\n",
       " ('longer', 199),\n",
       " ('anymore', 198),\n",
       " ('sampat', 198),\n",
       " ('obviously', 197),\n",
       " ('stick', 197),\n",
       " ('camp', 197),\n",
       " ('opened', 197),\n",
       " ('aiyah', 197),\n",
       " ('nose', 197),\n",
       " ('healthy', 196),\n",
       " ('chekowe', 196),\n",
       " ('sticker', 195),\n",
       " ('reading', 194),\n",
       " ('ha', 192),\n",
       " ('tho', 192),\n",
       " ('ppl', 191),\n",
       " ('lesser', 191),\n",
       " ('😭', 190),\n",
       " ('deal', 190),\n",
       " ('toto', 190),\n",
       " ('nights', 189),\n",
       " ('flight', 189),\n",
       " ('wish', 189),\n",
       " ('paid', 189),\n",
       " ('sign', 188),\n",
       " ('mee', 188),\n",
       " ('tsk', 187),\n",
       " ('games', 187),\n",
       " ('places', 187),\n",
       " ('screen', 187),\n",
       " ('surprise', 187),\n",
       " ('thursday', 186),\n",
       " ('rush', 186),\n",
       " ('ive', 185),\n",
       " ('words', 185),\n",
       " ('texting', 185),\n",
       " ('stayover', 185),\n",
       " ('tuesday', 184),\n",
       " ('min', 184),\n",
       " ('date', 184),\n",
       " ('lift', 184),\n",
       " ('hitch', 184),\n",
       " ('teeth', 184),\n",
       " ('giving', 183),\n",
       " ('nua', 183),\n",
       " ('fan', 183),\n",
       " ('matter', 183),\n",
       " ('possible', 183),\n",
       " ('news', 183),\n",
       " ('busy', 183),\n",
       " ('dad', 182),\n",
       " ('lady', 182),\n",
       " ('everyday', 182),\n",
       " ('bali', 182),\n",
       " ('correct', 182),\n",
       " ('managed', 180),\n",
       " ('plans', 180),\n",
       " ('dayre', 180),\n",
       " ('mention', 179),\n",
       " ('laughing', 179),\n",
       " ('nonsense', 179),\n",
       " ('lost', 178),\n",
       " ('chinese', 178),\n",
       " ('msg', 178),\n",
       " ('porridge', 178),\n",
       " ('dead', 177),\n",
       " ('middle', 177),\n",
       " ('video', 177),\n",
       " ('ultra', 177),\n",
       " ('sureee', 177),\n",
       " ('oi', 176),\n",
       " ('curry', 176),\n",
       " ('nowadays', 175),\n",
       " ('project', 175),\n",
       " ('sick', 175),\n",
       " ('follow', 175),\n",
       " ('per', 175),\n",
       " ('doesn’t', 175),\n",
       " ('luggage', 174),\n",
       " ('manage', 174),\n",
       " ('walked', 173),\n",
       " ('hk', 173),\n",
       " ('heavy', 173),\n",
       " ('lai', 172),\n",
       " ('along', 172),\n",
       " ('excited', 172),\n",
       " ('reason', 172),\n",
       " ('uber', 172),\n",
       " ('match', 171),\n",
       " ('somewhere', 171),\n",
       " ('prata', 171),\n",
       " ('data', 171),\n",
       " ('crazy', 170),\n",
       " ('okay', 169),\n",
       " ('anyone', 169),\n",
       " ('ooooh', 169),\n",
       " ('heng', 169),\n",
       " ('tw', 169),\n",
       " ('annoyed', 169),\n",
       " ('ntuc', 169),\n",
       " ('diff', 168),\n",
       " ('dapao', 168),\n",
       " ('ss', 168),\n",
       " ('green', 168),\n",
       " ('ordered', 168),\n",
       " ('staying', 168),\n",
       " ('smelly', 168),\n",
       " ('safe', 167),\n",
       " ('watched', 167),\n",
       " ('secretly', 167),\n",
       " ('apply', 167),\n",
       " ('properly', 167),\n",
       " ('paiseh', 167),\n",
       " ('meant', 167),\n",
       " ('max', 165),\n",
       " ('realised', 165),\n",
       " ('skip', 165),\n",
       " ('eye', 165),\n",
       " ('25', 165),\n",
       " ('specs', 165),\n",
       " ('gross', 164),\n",
       " ('forward', 164),\n",
       " ('looked', 164),\n",
       " ('steady', 164),\n",
       " ('social', 164),\n",
       " ('packing', 164),\n",
       " ('sofa', 164),\n",
       " ('sleepy', 163),\n",
       " ('smell', 163),\n",
       " ('easily', 163),\n",
       " ('whenever', 163),\n",
       " ('empty', 163),\n",
       " ('boyfriend', 163),\n",
       " ('snacks', 162),\n",
       " ('happen', 162),\n",
       " ('ticket', 161),\n",
       " ('fact', 161),\n",
       " ('update', 161),\n",
       " ('return', 161),\n",
       " ('fffc', 160),\n",
       " ('drank', 159),\n",
       " ('space', 159),\n",
       " ('soccer', 159),\n",
       " ('knew', 159),\n",
       " ('twice', 159),\n",
       " ('cooked', 159),\n",
       " ('convo', 159),\n",
       " ('singapore', 159),\n",
       " ('auntie', 159),\n",
       " ('koi', 159),\n",
       " ('choice', 158),\n",
       " ('total', 158),\n",
       " ('bet', 158),\n",
       " ('mai', 157),\n",
       " ('nobody', 157),\n",
       " ('gay', 157),\n",
       " ('bowl', 157),\n",
       " ('stories', 156),\n",
       " ('easier', 156),\n",
       " ('9pm', 156),\n",
       " ('aiyoh', 155),\n",
       " ('wasnt', 154),\n",
       " ('nowww', 153),\n",
       " ('hohoho', 153),\n",
       " ('fb', 153),\n",
       " ('lmk', 153),\n",
       " ('cooking', 153),\n",
       " ('40', 153),\n",
       " ('learn', 153),\n",
       " ('cab', 152),\n",
       " ('ot', 152),\n",
       " ('shiok', 152),\n",
       " ('double', 152),\n",
       " ('wew', 152),\n",
       " ('latest', 152),\n",
       " ('hold', 152),\n",
       " ('downstairs', 152),\n",
       " ('couldnt', 151),\n",
       " ('couple', 151),\n",
       " ('died', 150),\n",
       " ('listen', 150),\n",
       " ('zzz', 150),\n",
       " ('catch', 149),\n",
       " ('dabao', 148),\n",
       " ('move', 147),\n",
       " ('fri', 147),\n",
       " ('sold', 147),\n",
       " ('urghhh', 147),\n",
       " ('cc', 147),\n",
       " ('cover', 147),\n",
       " ('dirty', 146),\n",
       " ('smart', 146),\n",
       " ('kena', 146),\n",
       " ('heyyy', 146),\n",
       " ('lets', 146),\n",
       " ('roll', 146),\n",
       " ('aim', 145),\n",
       " ('non', 145),\n",
       " ('paper', 144),\n",
       " ('works', 144),\n",
       " ('future', 144),\n",
       " ('slow', 144),\n",
       " ('compared', 144),\n",
       " ('fault', 144),\n",
       " ('bigger', 144),\n",
       " ('730', 144),\n",
       " ('test', 144),\n",
       " ('workout', 144),\n",
       " ('booking', 144),\n",
       " ('🤗', 143),\n",
       " ('rmb', 143),\n",
       " ('spending', 142),\n",
       " ('shouldnt', 142),\n",
       " ('realized', 142),\n",
       " ('amk', 142),\n",
       " ...]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most common words in list of strings small caps\n",
    "\n",
    "wordCommon = Counter(smallflattenTextList) \n",
    "wordCommon.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words \t: frequency\n",
      "hello \t: 1357\n",
      "love \t: 948\n",
      "bye\t: 232\n",
      "lunch\t: 1950\n",
      "dinner\t: 2838\n",
      "chek\t: 356\n"
     ]
    }
   ],
   "source": [
    "print('words \\t: frequency')\n",
    "print('hello \\t: ' + str(smallflattenTextList.count('hello')))\n",
    "print('love \\t: ' + str(smallflattenTextList.count('love')))\n",
    "print('bye\\t: ' + str(smallflattenTextList.count('bye')))\n",
    "print('lunch\\t: ' + str(smallflattenTextList.count('lunch')))\n",
    "print('dinner\\t: ' + str(smallflattenTextList.count('dinner')))\n",
    "print('chek\\t: ' + str(smallflattenTextList.count('chek')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Analysis by word counts (Jiayin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                   [Hello, Jiayin, Cute, pic, btw, hahaha]\n",
       "3                             [Hahaha, time, studied, till]\n",
       "9                                  [hope, got, bed, hahaha]\n",
       "10        [supposed, wake, 10, snoozed, till, 12, part, ...\n",
       "17        [Siao, 35, hours, hahaha, unless, need, paper,...\n",
       "                                ...                        \n",
       "227312                    [still, got, lot, maggie, mee, 😂]\n",
       "227316                                        [okie, dokie]\n",
       "227317                                               [Hehe]\n",
       "227320    [Got, 2, small, prawns, scallops, mussels, hah...\n",
       "227323                               [HAHAHA, frozen, kind]\n",
       "Name: cleanText, Length: 106120, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['from']=='Jiayin']['cleanText'] # filter by partner's name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1                                             [HEYHEYHEY]\n",
       "2         [Omggg, dont, want, wake, feeling, like, DEATH]\n",
       "4                                            [slept, 630]\n",
       "5                              [Omg, snoozed, 10am, till]\n",
       "6                                [Really, need, get, bed]\n",
       "                               ...                       \n",
       "227319                                             [meat]\n",
       "227321                                          [mussels]\n",
       "227322                             [atas, suddenly, HAHA]\n",
       "227324                              [going, shower, alrd]\n",
       "227325                                   [facetime, hehe]\n",
       "Name: cleanText, Length: 121152, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['from']=='Chekwei']['cleanText'] # filter by my name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "jiayinTextList =[]\n",
    "for text in df[df['from']=='Jiayin']['cleanText']:\n",
    "    jiayinTextList.append(text) # text list is a list of list of strings, need to flatten - from JY only\n",
    "\n",
    "chekweiTextList = []\n",
    "for text in df[df['from']=='Chekwei']['cleanText']:\n",
    "    chekweiTextList.append(text) # text list is a list of list of strings, need to flatten - from me only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.core.common import flatten\n",
    "jiayinflattenTextList = list(flatten(jiayinTextList)) # list of tokenize strings after flatten\n",
    "chekweiflattenTextList = list(flatten(chekweiTextList)) # list of tokenize strings after flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "jymapOutput = map(lambda x:x.lower(), jiayinflattenTextList) \n",
    "cwmapOutput = map(lambda x:x.lower(), chekweiflattenTextList) \n",
    "\n",
    "jiayinsmallflattenTextList = list(jymapOutput) # list of tokenize strings in small caps\n",
    "chekweismallflattenTextList = list(cwmapOutput) # list of tokenize strings in small caps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hahaha', 16188),\n",
       " ('haha', 11028),\n",
       " ('ok', 7899),\n",
       " ('think', 6715),\n",
       " ('like', 6686),\n",
       " ('😂', 6221),\n",
       " ('one', 4726),\n",
       " ('nan', 4410),\n",
       " ('hahahaha', 4241),\n",
       " ('go', 3898)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 10 most common words in list of strings small caps from Jiayin\n",
    "\n",
    "jywordCommon = Counter(jiayinsmallflattenTextList) \n",
    "jywordCommon.most_common()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('haha', 9585),\n",
       " ('ok', 8677),\n",
       " ('hahaha', 8348),\n",
       " ('go', 6115),\n",
       " ('like', 5746),\n",
       " ('nan', 5233),\n",
       " ('think', 4758),\n",
       " ('one', 4372),\n",
       " ('okie', 4338),\n",
       " ('also', 4237)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 10 most common words in list of strings small caps from Chek\n",
    "\n",
    "cwwordCommon = Counter(chekweismallflattenTextList) \n",
    "cwwordCommon.most_common()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words from JY \t: frequency\n",
      "hi\t\t: 355\n",
      "hey\t\t: 72\n",
      "hahaha\t\t: 16188\n",
      "haha\t\t: 11028\n",
      "😂\t\t: 6221\n",
      "food\t\t: 994\n",
      "\n",
      "\n",
      "words from CW \t: frequency\n",
      "hi\t\t: 304\n",
      "hey\t\t: 228\n",
      "hahaha\t\t: 8348\n",
      "haha\t\t: 9585\n",
      "😂\t\t: 2888\n",
      "food\t\t: 1465\n"
     ]
    }
   ],
   "source": [
    "print('words from JY \\t: frequency')\n",
    "print('hi\\t\\t: ' + str(jiayinsmallflattenTextList.count('hi')))\n",
    "print('hey\\t\\t: ' + str(jiayinsmallflattenTextList.count('hey')))\n",
    "print('hahaha\\t\\t: ' + str(jiayinsmallflattenTextList.count('hahaha')))\n",
    "print('haha\\t\\t: ' + str(jiayinsmallflattenTextList.count('haha')))\n",
    "print('😂\\t\\t: ' + str(jiayinsmallflattenTextList.count('😂')))\n",
    "print('food\\t\\t: ' + str(jiayinsmallflattenTextList.count('food')))\n",
    "\n",
    "print('\\n')\n",
    "print('words from CW \\t: frequency')\n",
    "print('hi\\t\\t: ' + str(chekweismallflattenTextList.count('hi')))\n",
    "print('hey\\t\\t: ' + str(chekweismallflattenTextList.count('hey')))\n",
    "print('hahaha\\t\\t: ' + str(chekweismallflattenTextList.count('hahaha')))\n",
    "print('haha\\t\\t: ' + str(chekweismallflattenTextList.count('haha')))\n",
    "print('😂\\t\\t: ' + str(chekweismallflattenTextList.count('😂')))\n",
    "print('food\\t\\t: ' + str(chekweismallflattenTextList.count('food')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
