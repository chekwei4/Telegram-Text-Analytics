{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib.pyplot inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing unnecessary feature\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].astype('str') #converting data type to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textList = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords.words('english') #stopwords to be ignored/removed from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"'\n",
    "text_processing method does 3 things: \n",
    "1. remove punctuation\n",
    "2. remove stop words\n",
    "3. return list in clean text words (string)\n",
    "'\"\"\"\n",
    "\n",
    "def text_processing (text):\n",
    "    nopunc = [char for char in text if char not in string.punctuation]\n",
    "    \n",
    "    nopunc = ''.join(nopunc) \n",
    "    #making it become string of words, with blanks in between each word (proper sentence) \n",
    "    \n",
    "    #Example below:     \n",
    "    #['h','e','l','l','o','','c','h','e','k','','w','e','i']\n",
    "    #'hello chek wei'\n",
    "    #now, nopunc is a string form of words\n",
    "    return [word for word in nopunc.split()\n",
    "           if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating new feature = cleanText\n",
    "df['cleanText'] = df['text'].apply(text_processing) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleanText']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in df['cleanText']:\n",
    "    textList.append(text) #text list is a list of list of strings, need to flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.core.common import flatten\n",
    "flattenTextList = list(flatten(textList)) #list of tokenize strings after flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapOutput = map(lambda x:x.lower(), flattenTextList) \n",
    "smallflattenTextList = list(mapOutput) #list of tokenize strings in small caps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCommon = Counter(smallflattenTextList) #most common words in list of strings small caps\n",
    "wordCommon.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('words \\t: frequency')\n",
    "print('hello \\t: ' + str(smallflattenTextList.count('hello')))\n",
    "print('love \\t: ' + str(smallflattenTextList.count('love')))\n",
    "print('bye\\t: ' + str(smallflattenTextList.count('bye')))\n",
    "print('lunch\\t: ' + str(smallflattenTextList.count('lunch')))\n",
    "print('dinner\\t: ' + str(smallflattenTextList.count('dinner')))\n",
    "print('chek\\t: ' + str(smallflattenTextList.count('chek')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Analysis by word counts (Jiayin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['from']=='Jiayin']['cleanText'] #filter by partner's name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['from']=='Chekwei']['cleanText'] #filter by partner's name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jiayinTextList =[]\n",
    "for text in df[df['from']=='Jiayin']['cleanText']:\n",
    "    jiayinTextList.append(text) #text list is a list of list of strings, need to flatten - from JY only\n",
    "\n",
    "chekweiTextList = []\n",
    "for text in df[df['from']=='Chekwei']['cleanText']:\n",
    "    chekweiTextList.append(text) #text list is a list of list of strings, need to flatten - from CW only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.core.common import flatten\n",
    "jiayinflattenTextList = list(flatten(jiayinTextList)) # list of tokenize strings after flatten\n",
    "chekweiflattenTextList = list(flatten(chekweiTextList)) # list of tokenize strings after flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jymapOutput = map(lambda x:x.lower(), jiayinflattenTextList) \n",
    "cwmapOutput = map(lambda x:x.lower(), chekweiflattenTextList) \n",
    "\n",
    "jiayinsmallflattenTextList = list(jymapOutput) # list of tokenize strings in small caps\n",
    "chekweismallflattenTextList = list(cwmapOutput) # list of tokenize strings in small caps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jywordCommon = Counter(jiayinsmallflattenTextList) #most common words in list of strings small caps from Jiayin\n",
    "jywordCommon.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwwordCommon = Counter(chekweismallflattenTextList) #most common words in list of strings small caps from Chek\n",
    "cwwordCommon.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('words from JY \\t: frequency')\n",
    "print('hi\\t\\t: ' + str(jiayinsmallflattenTextList.count('hi')))\n",
    "print('hey\\t\\t: ' + str(jiayinsmallflattenTextList.count('hey')))\n",
    "print('hahaha\\t\\t: ' + str(jiayinsmallflattenTextList.count('hahaha')))\n",
    "print('haha\\t\\t: ' + str(jiayinsmallflattenTextList.count('haha')))\n",
    "print('ðŸ˜‚\\t\\t: ' + str(jiayinsmallflattenTextList.count('ðŸ˜‚')))\n",
    "print('food\\t\\t: ' + str(jiayinsmallflattenTextList.count('food')))\n",
    "\n",
    "print('\\n')\n",
    "print('words from CW \\t: frequency')\n",
    "print('hi\\t\\t: ' + str(chekweismallflattenTextList.count('hi')))\n",
    "print('hey\\t\\t: ' + str(chekweismallflattenTextList.count('hey')))\n",
    "print('hahaha\\t\\t: ' + str(chekweismallflattenTextList.count('hahaha')))\n",
    "print('haha\\t\\t: ' + str(chekweismallflattenTextList.count('haha')))\n",
    "print('ðŸ˜‚\\t\\t: ' + str(chekweismallflattenTextList.count('ðŸ˜‚')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
